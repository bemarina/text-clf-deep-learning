{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bemarina/text-clf-deep-learning/blob/main/pretrained-word-embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example with pretrained word embeddings (Keras documentation)"
      ],
      "metadata": {
        "id": "e1qofP_u2IcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import modules"
      ],
      "metadata": {
        "id": "QS4NTgo615Bl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tvtnh-I32Vp6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Only the TensorFlow backend supports string inputs.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import tensorflow.data as tf_data\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download and explore the data"
      ],
      "metadata": {
        "id": "ULfEP0n72VwW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "muFOk5eB2Vp8",
        "outputId": "33caa35a-89e8-4cbd-af9e-7ae2ba101c4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "17329808/17329808 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Download the Newsgroup20 data\n",
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])\n"
      ],
      "metadata": {
        "id": "SwaBseIL3kQs",
        "outputId": "288f84c1-2b58-401e-fd14-dd4e33c648a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['comp.os.ms-windows.misc', 'rec.motorcycles', 'talk.religion.misc', 'sci.electronics', 'sci.med', 'sci.space', 'comp.sys.ibm.pc.hardware', 'rec.autos', 'sci.crypt', 'misc.forsale', 'talk.politics.mideast', 'rec.sport.baseball', 'comp.sys.mac.hardware', 'soc.religion.christian', 'talk.politics.misc', 'rec.sport.hockey', 'alt.atheism', 'comp.windows.x', 'comp.graphics', 'talk.politics.guns']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['38802', '38553', '38396', '38832', '38658']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir"
      ],
      "metadata": {
        "id": "DwkhWPbn3kw9",
        "outputId": "a70cf711-68d3-4c84-83ac-cbd1791f69a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/20_newsgroup')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split data into training and validation sets"
      ],
      "metadata": {
        "id": "rnJ6HnNr2egA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "metadata": {
        "id": "gTIb8Ztu0iwP",
        "outputId": "3bbbaf4f-f092-4545-822d-ba6515bd5a16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(class_names)\n",
        "# 20 classes\n",
        "# almost 1000 files per class, so we can assume it's a balanced clf problem"
      ],
      "metadata": {
        "id": "jvvLCKN20jXD",
        "outputId": "69a805fe-5d5b-4cea-f4a6-79260628bf4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]\n"
      ],
      "metadata": {
        "id": "YJNG0QNH1PFN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(samples))\n",
        "samples[0]\n",
        "print(len(train_samples))\n",
        "print(len(val_samples))"
      ],
      "metadata": {
        "id": "ZYqQvHZ11TIg",
        "outputId": "4cfaa543-e949-4d99-bd59-9fd8544bff38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19997\n",
            "15998\n",
            "3999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Vocabulary index"
      ],
      "metadata": {
        "id": "JsoQGKNk1xq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use only 20,000 words and truncate/pad as necessary\n",
        "vectorizer = layers.TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf_data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "I0sIshRu124Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_vocabulary()[:5]"
      ],
      "metadata": {
        "id": "AngGqBf63FvR",
        "outputId": "a44aea54-9f3a-4635-fb49-00a18f1ff69d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing a test sentence\n",
        "output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "print(output.numpy()[0, :6])\n",
        "\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "metadata": {
        "id": "pXfTMPQ13Fl4",
        "outputId": "80847182-3c80-4480-a9f2-bcaea210fb77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2 3822 1767   15    2 6293]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = vectorizer([[\"the cat sat on the mat lashebet h h h h h h \"]])\n",
        "print(output.numpy())\n",
        "\n",
        "\n",
        "word_index['h']\n",
        "# 0 is for padding, 1 for words not in the vocabulary"
      ],
      "metadata": {
        "id": "5yFevPFrLkaT",
        "outputId": "c57b25e0-4810-49db-afcf-b85c46c1637a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   2 3822 1767   15    2 6293    1  864  864  864  864  864  864    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "864"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index['the']\n",
        "\n",
        "word_index['mat']\n",
        "count=0\n",
        "for k, v in word_index.items():\n",
        "  print(k,v)\n",
        "  count=count+1\n",
        "  if count>10:\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "9rbrMh783FcG",
        "outputId": "68cdb5b5-3113-4003-9cbb-2304520e409b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0\n",
            "[UNK] 1\n",
            "the 2\n",
            "to 3\n",
            "of 4\n",
            "a 5\n",
            "and 6\n",
            "in 7\n",
            "is 8\n",
            "i 9\n",
            "that 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained word embeddings\n",
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "JmKd_E85Iq5f",
        "outputId": "ba47d15f-ab51-47ad-b1ca-ccea4f17e93b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-04 22:34:27--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-11-04 22:37:06 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"glove.6B.100d.txt\",\"r\") as f:\n",
        "    print(len(f.readlines()))  # This would give length of files."
      ],
      "metadata": {
        "id": "QrfcyXBWKPD4",
        "outputId": "4ab080d1-8376-4274-adf2-5c33536bb3c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "with open(path_to_glove_file) as f:\n",
        "  count=0\n",
        "  for line in f:\n",
        "    count+=1\n",
        "    print(line)\n",
        "    if count>1:\n",
        "      break\n",
        "\n"
      ],
      "metadata": {
        "id": "BMP5pBI5J21J",
        "outputId": "6bebe90f-2bad-4317-fd2f-96e935ec8e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
            "\n",
            ", -0.10767 0.11053 0.59812 -0.54361 0.67396 0.10663 0.038867 0.35481 0.06351 -0.094189 0.15786 -0.81665 0.14172 0.21939 0.58505 -0.52158 0.22783 -0.16642 -0.68228 0.3587 0.42568 0.19021 0.91963 0.57555 0.46185 0.42363 -0.095399 -0.42749 -0.16567 -0.056842 -0.29595 0.26037 -0.26606 -0.070404 -0.27662 0.15821 0.69825 0.43081 0.27952 -0.45437 -0.33801 -0.58184 0.22364 -0.5778 -0.26862 -0.20425 0.56394 -0.58524 -0.14365 -0.64218 0.0054697 -0.35248 0.16162 1.1796 -0.47674 -2.7553 -0.1321 -0.047729 1.0655 1.1034 -0.2208 0.18669 0.13177 0.15117 0.7131 -0.35215 0.91348 0.61783 0.70992 0.23955 -0.14571 -0.37859 -0.045959 -0.47368 0.2385 0.20536 -0.18996 0.32507 -1.1112 -0.36341 0.98679 -0.084776 -0.54008 0.11726 -1.0194 -0.24424 0.12771 0.013884 0.080374 -0.35414 0.34951 -0.7226 0.37549 0.4441 -0.99059 0.61214 -0.35111 -0.83155 0.45293 0.082577\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "metadata": {
        "id": "M4ekYtMIIq1U",
        "outputId": "d6174596-5eaa-4793-f82a-852cc983674c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary index: each word is mapped to an index\n",
        "# if the word is not in the vocabulary, then the index is 1\n",
        "# if the sentence is shorter and we need padding, then the index is 0\n",
        "# to create a vector for a word: the columns are the words in the vocabulary\n",
        "# the initial vector would be (theoretically)  0 0 0 1 0 0 0\n",
        "# then these weights are updated during training to reflect similarities between\n",
        "# words or a closer/farther relation between words"
      ],
      "metadata": {
        "id": "MUhxXBS9Iqxm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in embeddings_index.items():\n",
        "  print(k, v)\n",
        "  print(len(v))\n",
        "  break\n",
        "\n",
        "# each word is mapped into 100 dimensions"
      ],
      "metadata": {
        "id": "_2Qf9d5TOuaq",
        "outputId": "af438d1f-62ee-427a-da47-395ee816332f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the [-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare embedding matrix for the words we have in the vocabulary\n",
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "id": "Cs8PHmwtPcpm",
        "outputId": "6999e4ad-8176-4bd5-d7a3-7f58b815a20a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 17996 words (2004 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(voc)==17992+2008\n"
      ],
      "metadata": {
        "id": "cUl8xRKlPjlT",
        "outputId": "4eed0abe-c178-4557-cd95-45456bcef42a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Embedding layer using the pretrained embeddings (so we set\n",
        "# trainable=False)\n",
        "# Using the embedding_matrix built above\n",
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    trainable=False,\n",
        ")\n",
        "embedding_layer.build((1,))\n",
        "embedding_layer.set_weights([embedding_matrix])"
      ],
      "metadata": {
        "id": "7cC75I4GP0yQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "# 1D convolution model with global max pooling and classifier at the end\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Rwa1nFNBQAu1",
        "outputId": "b1da955b-f0c1-4efd-c038-b7a23884a879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         2000200   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 128)         64128     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, None, 128)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, None, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, None, 128)         82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2247516 (8.57 MB)\n",
            "Trainable params: 247316 (966.08 KB)\n",
            "Non-trainable params: 2000200 (7.63 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPgoaQ6jRSvc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, convert our list-of-strings data to NumPy arrays of integer indices.\n",
        "# The arrays are right-padded.\n",
        "\n",
        "# Train the model\n",
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qsfo04nlQfla"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use categorical crossentropy as our loss since we're doing softmax\n",
        "# classification. Moreover, we use sparse_categorical_crossentropy since our\n",
        "# labels are integers.\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "CxhGVGXdQfcC",
        "outputId": "258839a9-7a26-417c-e135-25b158da26c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 4s 28ms/step - loss: 2.6272 - acc: 0.1494 - val_loss: 2.0285 - val_acc: 0.2841\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 1.9215 - acc: 0.3329 - val_loss: 1.6111 - val_acc: 0.4409\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 1.4927 - acc: 0.4847 - val_loss: 1.3222 - val_acc: 0.5329\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 1.2672 - acc: 0.5645 - val_loss: 1.1649 - val_acc: 0.6079\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 1.0958 - acc: 0.6220 - val_loss: 1.1355 - val_acc: 0.6272\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.9741 - acc: 0.6636 - val_loss: 1.0613 - val_acc: 0.6564\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.8518 - acc: 0.7065 - val_loss: 1.0366 - val_acc: 0.6694\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.7531 - acc: 0.7423 - val_loss: 1.0477 - val_acc: 0.6754\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.6687 - acc: 0.7705 - val_loss: 1.0078 - val_acc: 0.6872\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.5873 - acc: 0.7987 - val_loss: 1.0405 - val_acc: 0.6832\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 3s 26ms/step - loss: 0.5076 - acc: 0.8220 - val_loss: 1.1822 - val_acc: 0.6687\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.4395 - acc: 0.8457 - val_loss: 1.0404 - val_acc: 0.7034\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.3964 - acc: 0.8649 - val_loss: 1.1156 - val_acc: 0.6924\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.3417 - acc: 0.8850 - val_loss: 1.1443 - val_acc: 0.7012\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.2972 - acc: 0.8977 - val_loss: 1.2421 - val_acc: 0.7019\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 3s 26ms/step - loss: 0.2594 - acc: 0.9137 - val_loss: 1.2144 - val_acc: 0.7002\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.2511 - acc: 0.9165 - val_loss: 1.2780 - val_acc: 0.6942\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 3s 26ms/step - loss: 0.2244 - acc: 0.9249 - val_loss: 1.2945 - val_acc: 0.7064\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 3s 26ms/step - loss: 0.2074 - acc: 0.9314 - val_loss: 1.3587 - val_acc: 0.7062\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 3s 25ms/step - loss: 0.1777 - acc: 0.9421 - val_loss: 1.4155 - val_acc: 0.7002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1e6872ccd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "JDZy8FmEWPek",
        "outputId": "4012e664-ee36-44c7-9f99-7d427d6a43d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model(\n",
        "    tf.convert_to_tensor(\n",
        "        [[\"this message is about computer graphics and 3D modeling\"]]\n",
        "    )\n",
        ")\n",
        "\n",
        "print(class_names[np.argmax(probabilities[0])])\n"
      ],
      "metadata": {
        "id": "eeU5xLUcShdj",
        "outputId": "54ce2e97-d27e-45ba-90d7-a57fbc1d5264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.convert_to_tensor(\n",
        "        [[\"there are a lot of electronic items in my house\"]]\n",
        "    )\n",
        "\n",
        "predictions = end_to_end_model(input_data)\n"
      ],
      "metadata": {
        "id": "IN8nB8kzW7Xw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = tf.convert_to_tensor(\n",
        "        [[\"there are 3 phones, 3 laptops, 1 TV and 1 car in my house\"]]\n",
        "    )\n",
        "\n",
        "predictions = end_to_end_model(input_data)\n"
      ],
      "metadata": {
        "id": "oEQ3lCIEXuII"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 classes\n",
        "np.argmax(predictions[0])\n",
        "class_names[np.argmax(predictions[0])]"
      ],
      "metadata": {
        "id": "0f131wUHXa9Y",
        "outputId": "d7fa665c-cac0-4047-c0d2-9a5c45a0cc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'misc.forsale'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model in Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wt0DTp4NX6of",
        "outputId": "94563f3e-e012-433f-ebb7-26be8c8e2b15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-8735bd6e5c80>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save the model in Google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJOqiINRZIsQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}